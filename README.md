# ğŸ•Œ Lucknow Tehzeeb Interpreter

**Kiro Heroes Week 5 Challenge: "The Local Guide"**

AI-powered cultural interpreter that decodes Lucknow's indirect communication and polite phrases using custom Kiro context.

## ğŸŒ Live Deployments

- **Frontend**: https://lucknow-kiro-guide-5t9d-d8nksu1si.vercel.app/
- **Backend API**: https://lucknow-kiro-guide-rfcdk5svj-rvsrathore17-gmailcoms-projects.vercel.app
- **GitHub**: https://github.com/something1703/lucknow-kiro-guide

## ğŸ¯ Challenge Overview

**Task**: Build a local guide using custom context (product.md)  
**Solution**: Lucknow cultural interpreter with 49,031 characters of knowledge  
**Tech**: React + Express + OpenAI GPT-4o-mini + Kiro Architecture

## ğŸ§  The Kiro Approach

This project uses `.kiro/product.md` (928 lines) to encode:
- Phrase entries with implied meanings
- Behavioral rules for indirect communication  
- Tone analysis frameworks
- Social appropriateness guidelines

The backend loads this context on every request (49,031 chars), steering AI from generic to culturally-aware responses.

## âœ¨ Features

- ğŸ¨ Glass Morphism UI with Lucknow background
- ğŸ’­ Implied Meaning interpretation
- ğŸ­ Tone Category analysis
- ğŸ“ Usage Context detection
- âœ“ Social Appropriateness scoring
- âš ï¸ Cultural Risk warnings
- ğŸ”„ **Smart Fallback**: When AI is unavailable, automatically parses product.md for direct matches

## ğŸ—ï¸ Architecture

**Dual-Mode Operation**:
1. **AI Mode** (Primary): OpenAI GPT-4o-mini with full 49KB context
2. **Fallback Mode** (Backup): Direct product.md parsing when AI unavailable

**Environment-Based Config**:
- Local dev: `http://localhost:3001` (from `.env.local`)
- Production: Vercel backend URL (from `.env.production`)

## ğŸš€ Quick Start

```bash
# Clone
git clone https://github.com/something1703/lucknow-kiro-guide.git
cd lucknow-kiro-guide

# Backend
cd server
npm install
cp .env.example .env
# Add OPENAI_API_KEY to .env
npm run dev

# Frontend (new terminal)
cd ../app
npm install
npm start
```

Visit: http://localhost:3000

## ğŸ“ Structure

```
â”œâ”€â”€ .kiro/product.md    # 928 lines of cultural knowledge (REQUIRED)
â”œâ”€â”€ app/                # React frontend
â””â”€â”€ server/             # Express API
```

## ğŸ† Hackathon Compliance

âœ… Custom context (`.kiro/product.md`)  
âœ… Encodes Lucknow cultural nuances  
âœ… `.kiro/` at project root  
âœ… Public GitHub repo

## ğŸ› ï¸ Tech Stack

- React 18 + Glass Morphism CSS
- Express.js + Node.js
- OpenAI GPT-4o-mini
- Kiro knowledge base pattern
- Manual fallback parser

## ğŸ“ Environment

**Backend** (`server/.env`):
```env
OPENAI_API_KEY=sk-your-key-here
PORT=3001
```

**Frontend** (`.env.local` for dev, `.env.production` for build):
```env
REACT_APP_API_URL=http://localhost:3001
```

## âš ï¸ Known Issues & Solutions

### Production Deployment
- **Issue**: OpenAI API rate limits on free tier (3 req/min)
- **Solution**: Smart fallback automatically searches product.md when AI fails
- **Fix**: Add payment method to OpenAI account for higher limits

### Local vs Production
- **Solution**: Environment variables auto-detect local vs production
- Local: Uses `localhost:3001`
- Production: Uses Vercel backend URL

## ğŸš€ What Works

âœ… **Local Development**: Full AI + manual fallback working  
âœ… **GitHub Repo**: Complete with .kiro/ directory  
âœ… **Frontend Deployed**: Live on Vercel  
âœ… **Backend Deployed**: API endpoints accessible  
âœ… **Context Loading**: 49,031 characters loaded successfully  
âœ… **Fallback System**: Parses product.md when AI unavailable

---

**Built with â¤ï¸ for Kiro Heroes Week 5**
